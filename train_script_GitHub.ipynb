{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa402af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.9.dev2209\n",
      "Numpy version: 1.21.5\n",
      "Pytorch version: 1.10.2\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 9db6e543d6090a3256f20695c1d3224df8cbbc0e\n",
      "MONAI __file__: C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.8\n",
      "Nibabel version: 3.2.2\n",
      "scikit-image version: 0.19.2\n",
      "Pillow version: 9.0.1\n",
      "Tensorboard version: 2.8.0\n",
      "gdown version: 4.2.1\n",
      "TorchVision version: 0.11.3\n",
      "tqdm version: 4.63.0\n",
      "lmdb version: 1.3.0\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.4.1\n",
      "einops version: 0.4.0\n",
      "transformers version: 4.16.2\n",
      "mlflow version: 1.23.1\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import glob\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.utils import first, set_determinism\n",
    "\n",
    "import monai\n",
    "from monai.data import create_test_image_3d, list_data_collate, decollate_batch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    Resized,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    Activationsd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    ScaleIntensityd,\n",
    "    SaveImaged,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Invertd,\n",
    ")\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "from monai.config import print_config\n",
    "print_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "510ee5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.9.dev2209\n",
      "Numpy version: 1.21.5\n",
      "Pytorch version: 1.10.2\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 9db6e543d6090a3256f20695c1d3224df8cbbc0e\n",
      "MONAI __file__: C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.8\n",
      "Nibabel version: 3.2.2\n",
      "scikit-image version: 0.19.2\n",
      "Pillow version: 9.0.1\n",
      "Tensorboard version: 2.8.0\n",
      "gdown version: 4.2.1\n",
      "TorchVision version: 0.11.3\n",
      "tqdm version: 4.63.0\n",
      "lmdb version: 1.3.0\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.4.1\n",
      "einops version: 0.4.0\n",
      "transformers version: 4.16.2\n",
      "mlflow version: 1.23.1\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 177>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    175\u001b[0m     writer\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 178\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(root_dir)\u001b[0m\n\u001b[0;32m     49\u001b[0m check_loader \u001b[38;5;241m=\u001b[39m DataLoader(check_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     50\u001b[0m check_data \u001b[38;5;241m=\u001b[39m first(check_loader)\n\u001b[1;32m---> 51\u001b[0m image, label \u001b[38;5;241m=\u001b[39m (\u001b[43mcheck_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m], check_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, mask shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# create a training data loader\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "root_dir  = '../projects/CTPelvic1K_data/root_dir'\n",
    "\n",
    "def main(root_dir):\n",
    "    monai.config.print_config()\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    \n",
    "    train_images = sorted(glob.glob(os.path.join(root_dir, \"*data.nii.gz\")))\n",
    "    train_labels = sorted(glob.glob(os.path.join(root_dir, \"*mask_4label.nii.gz\")))\n",
    "    data_dicts = [{\"image\": image_name, \"mask\": label_name} for image_name, label_name in zip(train_images, train_labels)]\n",
    "    train_files, val_files = data_dicts[:-6], data_dicts[-6:]\n",
    "\n",
    "    # define transforms for image and segmentation\n",
    "    train_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"mask\"]),\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"mask\"]),\n",
    "            Orientationd(keys=[\"image\", \"mask\"], axcodes=\"RAS\"),\n",
    "            Spacingd(keys=[\"image\", \"mask\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=-120, a_max=360,b_min=0.0, b_max=1.0, clip=True,),\n",
    "            CropForegroundd(keys=[\"image\", \"mask\"], source_key=\"image\"),\n",
    "            RandCropByPosNegLabeld(\n",
    "                keys=[\"image\", \"mask\"],\n",
    "                label_key=\"mask\",\n",
    "                spatial_size=(128, 128, 128),\n",
    "                pos=1,\n",
    "                neg=1,\n",
    "                num_samples=4,\n",
    "                image_key=\"image\",\n",
    "                image_threshold=0,\n",
    "        ),\n",
    "            EnsureTyped(keys=[\"image\", \"mask\"]),\n",
    "        ]\n",
    "    )\n",
    "    val_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"mask\"]),\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"mask\"]),\n",
    "            Orientationd(keys=[\"image\", \"mask\"], axcodes=\"RAS\"),\n",
    "            Spacingd(keys=[\"image\", \"mask\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=-120, a_max=360,b_min=0.0, b_max=1.0, clip=True,),\n",
    "            CropForegroundd(keys=[\"image\", \"mask\"], source_key=\"image\"),\n",
    "            EnsureTyped(keys=[\"image\", \"mask\"]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    \n",
    "    # define dataset, data loader\n",
    "    check_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "    check_loader = DataLoader(check_ds, batch_size=1)\n",
    "    check_data = first(check_loader)\n",
    "    image, label = (check_data[\"image\"][0], check_data[\"mask\"][0])\n",
    "    print(f\"image shape: {image.shape}, mask shape: {label.shape}\")\n",
    "\n",
    "\n",
    "    # create a training data loader\n",
    "    \n",
    "    train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "    train_loader = DataLoader(train_ds, batch_size=2, num_workers=0)\n",
    "    \n",
    "    # create a validation data loader\n",
    "    val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=0)\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    # create UNet, DiceLoss and Adam optimizer\n",
    "    device=torch.device(\"cuda:0\")  \n",
    "    model = monai.networks.nets.UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=5,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "    ).to(device)\n",
    "    loss_function = DiceCELoss(to_onehot_y=True, softmax=True) \n",
    "    optimizer = torch.optim.Adam(model.parameters(), 2e-4)\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "    \n",
    "    VAL_AMP = True\n",
    "    # define inference method\n",
    "    def inference(input):\n",
    "        def _compute(input):\n",
    "            return sliding_window_inference(inputs=input, roi_size=(160, 160, 160), sw_batch_size=4, predictor=model, overlap=0.5,)\n",
    "\n",
    "        if VAL_AMP:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                return _compute(input)\n",
    "        else:\n",
    "            return _compute(input)\n",
    "    \n",
    "    # use amp to accelerate training\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    # enable cuDNN benchmark\n",
    "    torch.backends.cudnn.benchmark = True    \n",
    "    \n",
    "\n",
    "    # start a typical PyTorch training\n",
    "    max_epochs = 400\n",
    "    val_interval = 1\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    \n",
    "    epoch_loss_values = []\n",
    "    metric_values = []\n",
    "    post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=5)])\n",
    "    post_label = Compose([EnsureType(), AsDiscrete(to_onehot=5)])\n",
    "    writer = SummaryWriter()\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "        \n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs, labels = batch_data[\"image\"].to(device), batch_data[\"mask\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_len = len(train_ds) // train_loader.batch_size\n",
    "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "        \n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for val_data in val_loader:\n",
    "                    val_inputs, val_labels = (val_data[\"image\"].to(device), val_data[\"mask\"].to(device),)\n",
    "                    val_outputs = inference(val_inputs)\n",
    "                    val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                    val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                \n",
    "                    # compute metric for current iteration\n",
    "                    dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                \n",
    "                # aggregate the final mean dice result\n",
    "                metric = dice_metric.aggregate().item()\n",
    "                # reset the status for next validation round\n",
    "                dice_metric.reset()\n",
    "\n",
    "                metric_values.append(metric)\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), os.path.join(root_dir, \"3DUnet_best_metric_model.pth\"))\n",
    "                    print(\"saved new best metric model\")\n",
    "                \n",
    "                print(\n",
    "                    f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                    f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "                    f\"at epoch: {best_metric_epoch}\"\n",
    "                )\n",
    "                \n",
    "                writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
    "                # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "                plot_2d_or_3d_image(val_inputs, epoch + 1, writer, index=0, tag=\"image\")\n",
    "                plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"mask\")\n",
    "                plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "\n",
    "    print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "    writer.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261831d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09067f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
