{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2597e154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.9.dev2209\n",
      "Numpy version: 1.21.5\n",
      "Pytorch version: 1.10.2\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 9db6e543d6090a3256f20695c1d3224df8cbbc0e\n",
      "MONAI __file__: C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.8\n",
      "Nibabel version: 3.2.2\n",
      "scikit-image version: 0.19.2\n",
      "Pillow version: 9.0.1\n",
      "Tensorboard version: 2.8.0\n",
      "gdown version: 4.2.1\n",
      "TorchVision version: 0.11.3\n",
      "tqdm version: 4.63.0\n",
      "lmdb version: 1.3.0\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.4.1\n",
      "einops version: 0.4.0\n",
      "transformers version: 4.16.2\n",
      "mlflow version: 1.23.1\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████| 31/31 [05:01<00:00,  9.73s/it]\n",
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████| 10/10 [01:29<00:00,  8.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ignite.engine.engine.SupervisedTrainer:Engine run resuming from iteration 0, epoch 0 until 500 epochs\n",
      "ERROR:ignite.engine.engine.SupervisedTrainer:Current run is terminating due to exception: 'NoneType' object has no attribute 'shape'\n",
      "2022-04-12 20:21:42,026 - ERROR - Exception: 'NoneType' object has no attribute 'shape'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\ignite\\engine\\engine.py\", line 840, in _run_once_on_dataset\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\engines\\trainer.py\", line 204, in _iteration\n",
      "    _compute_pred_loss()\n",
      "  File \"C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\engines\\trainer.py\", line 192, in _compute_pred_loss\n",
      "    engine.state.output[Keys.LOSS] = self.loss_function(engine.state.output[Keys.PRED], targets).mean()\n",
      "  File \"C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\losses\\dice.py\", line 722, in forward\n",
      "    if len(input.shape) != len(target.shape):\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n",
      "ERROR:ignite.engine.engine.SupervisedTrainer:Engine run is terminating due to exception: 'NoneType' object has no attribute 'shape'\n",
      "2022-04-12 20:21:42,030 - ERROR - Exception: 'NoneType' object has no attribute 'shape'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\ignite\\engine\\engine.py\", line 753, in _internal_run\n",
      "    time_taken = self._run_once_on_dataset()\n",
      "  File \"C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\ignite\\engine\\engine.py\", line 854, in _run_once_on_dataset\n",
      "    self._handle_exception(e)\n",
      "  File \"C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\ignite\\engine\\engine.py\", line 464, in _handle_exception\n",
      "    self._fire_event(Events.EXCEPTION_RAISED, e)\n",
      "  File \"C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\ignite\\engine\\engine.py\", line 421, in _fire_event\n",
      "    func(*first, *(event_args + others), **kwargs)\n",
      "  File \"C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\handlers\\stats_handler.py\", line 173, in exception_raised\n",
      "    raise e\n",
      "  File \"C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\ignite\\engine\\engine.py\", line 840, in _run_once_on_dataset\n",
      "    self.state.output = self._process_function(self, self.state.batch)\n",
      "  File \"C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\engines\\trainer.py\", line 204, in _iteration\n",
      "    _compute_pred_loss()\n",
      "  File \"C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\engines\\trainer.py\", line 192, in _compute_pred_loss\n",
      "    engine.state.output[Keys.LOSS] = self.loss_function(engine.state.output[Keys.PRED], targets).mean()\n",
      "  File \"C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\losses\\dice.py\", line 722, in forward\n",
      "    if len(input.shape) != len(target.shape):\n",
      "AttributeError: 'NoneType' object has no attribute 'shape'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 198>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    195\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 199\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(train_dir)\u001b[0m\n\u001b[0;32m    193\u001b[0m val_handlers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_trainer(trainer\u001b[38;5;241m=\u001b[39mtrainer)\n\u001b[0;32m    194\u001b[0m train_handlers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_trainer(trainer\u001b[38;5;241m=\u001b[39mtrainer)\n\u001b[1;32m--> 195\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\engines\\trainer.py:56\u001b[0m, in \u001b[0;36mTrainer.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03mExecute training based on Ignite Engine.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03mIf call this function multiple times, it will continuously run from the previous state.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mGradScaler() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\engines\\workflow.py:282\u001b[0m, in \u001b[0;36mWorkflow.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    276\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`dataloader` is emply or the specified `epoch_length` is 0, skip the `run`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m if running distributed training, the program may hang in `all-gather`, `all-reduce`, etc.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m because not all the ranks run the same computation logic.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\ignite\\engine\\engine.py:704\u001b[0m, in \u001b[0;36mEngine.run\u001b[1;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch_length should be provided if data is None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m--> 704\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\ignite\\engine\\engine.py:783\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 783\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\ignite\\engine\\engine.py:464\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_exception\u001b[39m(\u001b[38;5;28mself\u001b[39m, e: \u001b[38;5;167;01mBaseException\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_handlers:\n\u001b[1;32m--> 464\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fire_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEXCEPTION_RAISED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\ignite\\engine\\engine.py:421\u001b[0m, in \u001b[0;36mEngine._fire_event\u001b[1;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[0;32m    419\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(event_kwargs)\n\u001b[0;32m    420\u001b[0m first, others \u001b[38;5;241m=\u001b[39m ((args[\u001b[38;5;241m0\u001b[39m],), args[\u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;28;01mif\u001b[39;00m (args \u001b[38;5;129;01mand\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m ((), args)\n\u001b[1;32m--> 421\u001b[0m func(\u001b[38;5;241m*\u001b[39mfirst, \u001b[38;5;241m*\u001b[39m(event_args \u001b[38;5;241m+\u001b[39m others), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\handlers\\stats_handler.py:173\u001b[0m, in \u001b[0;36mStatsHandler.exception_raised\u001b[1;34m(self, _engine, e)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mHandler for train or validation/evaluation exception raised Event.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03mPrint the exception information and traceback. This callback may be skipped because the logic\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m \n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\ignite\\engine\\engine.py:753\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[1;32m--> 753\u001b[0m time_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once_on_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be update after fire\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m time_taken\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\ignite\\engine\\engine.py:854\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 854\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\ignite\\engine\\engine.py:464\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_exception\u001b[39m(\u001b[38;5;28mself\u001b[39m, e: \u001b[38;5;167;01mBaseException\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_handlers:\n\u001b[1;32m--> 464\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fire_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEXCEPTION_RAISED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\ignite\\engine\\engine.py:421\u001b[0m, in \u001b[0;36mEngine._fire_event\u001b[1;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[0;32m    419\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(event_kwargs)\n\u001b[0;32m    420\u001b[0m first, others \u001b[38;5;241m=\u001b[39m ((args[\u001b[38;5;241m0\u001b[39m],), args[\u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;28;01mif\u001b[39;00m (args \u001b[38;5;129;01mand\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m ((), args)\n\u001b[1;32m--> 421\u001b[0m func(\u001b[38;5;241m*\u001b[39mfirst, \u001b[38;5;241m*\u001b[39m(event_args \u001b[38;5;241m+\u001b[39m others), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\handlers\\stats_handler.py:173\u001b[0m, in \u001b[0;36mStatsHandler.exception_raised\u001b[1;34m(self, _engine, e)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mHandler for train or validation/evaluation exception raised Event.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03mPrint the exception information and traceback. This callback may be skipped because the logic\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m \n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\ignite\\engine\\engine.py:840\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39miteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[1;32m--> 840\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_COMPLETED)\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_terminate \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_terminate_single_epoch:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\engines\\trainer.py:204\u001b[0m, in \u001b[0;36mSupervisedTrainer._iteration\u001b[1;34m(self, engine, batchdata)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[1;32m--> 204\u001b[0m         \u001b[43m_compute_pred_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(engine\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput[Keys\u001b[38;5;241m.\u001b[39mLOSS])\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    206\u001b[0m     engine\u001b[38;5;241m.\u001b[39mfire_event(IterationEvents\u001b[38;5;241m.\u001b[39mBACKWARD_COMPLETED)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\engines\\trainer.py:192\u001b[0m, in \u001b[0;36mSupervisedTrainer._iteration.<locals>._compute_pred_loss\u001b[1;34m()\u001b[0m\n\u001b[0;32m    190\u001b[0m engine\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput[Keys\u001b[38;5;241m.\u001b[39mPRED] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minferer(inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    191\u001b[0m engine\u001b[38;5;241m.\u001b[39mfire_event(IterationEvents\u001b[38;5;241m.\u001b[39mFORWARD_COMPLETED)\n\u001b[1;32m--> 192\u001b[0m engine\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput[Keys\u001b[38;5;241m.\u001b[39mLOSS] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[43mKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPRED\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m    193\u001b[0m engine\u001b[38;5;241m.\u001b[39mfire_event(IterationEvents\u001b[38;5;241m.\u001b[39mLOSS_COMPLETED)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\losses\\dice.py:722\u001b[0m, in \u001b[0;36mDiceCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor, target: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;124;03m        input: the shape should be BNH[WD].\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    720\u001b[0m \n\u001b[0;32m    721\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m):\n\u001b[0;32m    723\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe number of dimensions for input and target should be the same.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    725\u001b[0m     dice_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdice(\u001b[38;5;28minput\u001b[39m, target)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "from ignite.metrics import Accuracy\n",
    "\n",
    "import monai\n",
    "from monai.apps import get_logger\n",
    "from monai.data import create_test_image_3d\n",
    "from monai.networks.layers import Norm\n",
    "from monai.engines import SupervisedEvaluator, SupervisedTrainer\n",
    "from monai.handlers import (\n",
    "    CheckpointSaver,\n",
    "    EarlyStopHandler,\n",
    "    LrScheduleHandler,\n",
    "    MeanDice,\n",
    "    StatsHandler,\n",
    "    TensorBoardImageHandler,\n",
    "    TensorBoardStatsHandler,\n",
    "    ValidationHandler,\n",
    "    from_engine,\n",
    ")\n",
    "from monai.inferers import SimpleInferer, SlidingWindowInferer\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    Activationsd,\n",
    "    AsChannelFirstd,\n",
    "    Orientationd,\n",
    "    EnsureChannelFirstd,\n",
    "    AsDiscreted,\n",
    "    Spacingd,\n",
    "    Compose,\n",
    "    KeepLargestConnectedComponentd,\n",
    "    LoadImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    CropForegroundd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    "    EnsureTyped,\n",
    ")\n",
    "\n",
    "train_dir  = 'C:/Users/Hripsime/OneDrive - ABYS MEDICAL/projects/CTPelvic1K_data/train_dir'\n",
    "\n",
    "def main(train_dir):\n",
    "    monai.config.print_config()\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    get_logger(\"train_log\")\n",
    "\n",
    "    train_images = sorted(glob.glob(os.path.join(train_dir, \"*data.nii.gz\")))\n",
    "    train_labels = sorted(glob.glob(os.path.join(train_dir, \"*mask_4label.nii.gz\")))\n",
    "    data_dicts = [{\"image\": image_name, \"mask\": label_name} for image_name, label_name in zip(train_images, train_labels)]\n",
    "    train_files, val_files = data_dicts[:-10], data_dicts[-10:]\n",
    "    \n",
    "    \n",
    "    # define transforms for image and segmentation\n",
    "    train_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"mask\"]),\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"mask\"]),\n",
    "            Orientationd(keys=[\"image\", \"mask\"], axcodes=\"RAS\"),\n",
    "            Spacingd(keys=[\"image\", \"mask\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=-120, a_max=360,b_min=0.0, b_max=1.0, clip=True,),\n",
    "            CropForegroundd(keys=[\"image\", \"mask\"], source_key=\"image\"),\n",
    "            RandCropByPosNegLabeld(\n",
    "                keys=[\"image\", \"mask\"],\n",
    "                label_key=\"mask\",\n",
    "                spatial_size=(128, 128, 128),\n",
    "                pos=1,\n",
    "                neg=1,\n",
    "                num_samples=4,\n",
    "                image_key=\"image\",\n",
    "                image_threshold=0,\n",
    "        ),\n",
    "            EnsureTyped(keys=[\"image\", \"mask\"]),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    val_transforms = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"mask\"]),\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"mask\"]),\n",
    "            Orientationd(keys=[\"image\", \"mask\"], axcodes=\"RAS\"),\n",
    "            Spacingd(keys=[\"image\", \"mask\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n",
    "            ScaleIntensityRanged(keys=[\"image\"], a_min=-120, a_max=360,b_min=0.0, b_max=1.0, clip=True,),\n",
    "            CropForegroundd(keys=[\"image\", \"mask\"], source_key=\"image\"),\n",
    "            EnsureTyped(keys=[\"image\", \"mask\"]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # create a training data loader\n",
    "    train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=0)\n",
    "    train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "    # create a validation data loader\n",
    "    val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, num_workers=0)\n",
    "    \n",
    "    \n",
    "    # create UNet, DiceLoss and Adam optimizer\n",
    "    device=torch.device(\"cuda:0\")  \n",
    "    net = UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=5,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "        norm=Norm.BATCH,\n",
    "    ).to(device)\n",
    "    loss = monai.losses.DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "    opt = torch.optim.Adam(net.parameters(), 2e-4)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=1, gamma=0.1)\n",
    "\n",
    "    val_post_transforms = Compose(\n",
    "        [\n",
    "            EnsureTyped(keys=\"pred\"),\n",
    "            Activationsd(keys=\"pred\", sigmoid=True),\n",
    "            AsDiscreted(keys=\"pred\", threshold=0.5),\n",
    "            KeepLargestConnectedComponentd(keys=\"pred\", applied_labels=[5]),\n",
    "        ]\n",
    "    )\n",
    "    val_handlers = [\n",
    "        # apply “EarlyStop” logic based on the validation metrics\n",
    "        EarlyStopHandler(trainer=None, patience=20, score_function=lambda x: x.state.metrics[\"val_mean_dice\"]),\n",
    "        # use the logger \"train_log\" defined at the beginning of this program\n",
    "        StatsHandler(name=\"train_log\", output_transform=lambda x: None),\n",
    "        TensorBoardStatsHandler(log_dir=\"./runs/\", output_transform=lambda x: None),\n",
    "        TensorBoardImageHandler(\n",
    "            log_dir=\"./runs/\",\n",
    "            batch_transform=from_engine([\"image\", \"mask\"]),\n",
    "            output_transform=from_engine([\"pred\"]),\n",
    "        ),\n",
    "        CheckpointSaver(save_dir=\"./runs/\", save_dict={\"net\": net}, save_key_metric=True),\n",
    "    ]\n",
    "\n",
    "    evaluator = SupervisedEvaluator(\n",
    "        device=device,\n",
    "        val_data_loader=val_loader,\n",
    "        network=net,\n",
    "        inferer=SlidingWindowInferer(roi_size=(160, 160, 160), sw_batch_size=4, overlap=0.5),\n",
    "        postprocessing=val_post_transforms,\n",
    "        key_val_metric={\n",
    "            \"val_mean_dice\": MeanDice(include_background=True, output_transform=from_engine([\"pred\", \"mask\"]))\n",
    "        },\n",
    "        additional_metrics={\"val_acc\": Accuracy(output_transform=from_engine([\"pred\", \"mask\"]))},\n",
    "        val_handlers=val_handlers,\n",
    "        # if no FP16 support in GPU or PyTorch version < 1.6, will not enable AMP evaluation\n",
    "        amp=True if monai.utils.get_torch_version_tuple() >= (1, 6) else False,\n",
    "    )\n",
    "\n",
    "    train_post_transforms = Compose(\n",
    "        [\n",
    "            Activationsd(keys=\"pred\", sigmoid=True),\n",
    "            AsDiscreted(keys=\"pred\", threshold=0.5),\n",
    "            KeepLargestConnectedComponentd(keys=\"pred\", applied_labels=[5]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_handlers = [\n",
    "        # apply “EarlyStop” logic based on the loss value, use “-” negative value because smaller loss is better\n",
    "        EarlyStopHandler(trainer=None, patience=20, score_function=lambda x: -x.state.output[0][\"loss\"], epoch_level=False),\n",
    "        LrScheduleHandler(lr_scheduler=lr_scheduler, print_lr=True),\n",
    "        ValidationHandler(validator=evaluator, interval=1, epoch_level=True),\n",
    "        # use the logger \"train_log\" defined at the beginning of this program\n",
    "        StatsHandler(name=\"train_log\", tag_name=\"train_loss\", output_transform=from_engine([\"loss\"], first=True)),\n",
    "        TensorBoardStatsHandler(log_dir=\"./runs/\", tag_name=\"train_loss\", output_transform=from_engine([\"loss\"], first=True)),\n",
    "        CheckpointSaver(save_dir=\"./runs/\", save_dict={\"net\": net, \"opt\": opt}, save_interval=1, epoch_level=True),\n",
    "    ]\n",
    "\n",
    "    trainer = SupervisedTrainer(\n",
    "        device=device,\n",
    "        max_epochs=500,\n",
    "        train_data_loader=train_loader,\n",
    "        network=net,\n",
    "        optimizer=opt,\n",
    "        loss_function=loss,\n",
    "        inferer=SimpleInferer(),\n",
    "        postprocessing=train_post_transforms,\n",
    "        key_train_metric={\"train_acc\": Accuracy(output_transform=from_engine([\"pred\", \"mask\"]))},\n",
    "        train_handlers=train_handlers,\n",
    "        # if no FP16 support in GPU or PyTorch version < 1.6, will not enable AMP training\n",
    "        amp=True if monai.utils.get_torch_version_tuple() >= (1, 6) else False,\n",
    "    )\n",
    "    # set initialized trainer for \"early stop\" handlers\n",
    "    val_handlers[0].set_trainer(trainer=trainer)\n",
    "    train_handlers[0].set_trainer(trainer=trainer)\n",
    "    trainer.run()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb1f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
