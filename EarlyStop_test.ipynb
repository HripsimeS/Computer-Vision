{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "615d3ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1e43cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0: background,\\n1: sacrum,\\n2: right_hip,\\n3: left_hip,\\n4: lumbar_vertebra.        \\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "0: background,\n",
    "1: sacrum,\n",
    "2: right_hip,\n",
    "3: left_hip,\n",
    "4: lumbar_vertebra.        \n",
    "\"\"\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c7e6efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import EarlyStopping\n",
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3f6631f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.9.dev2209\n",
      "Numpy version: 1.21.5\n",
      "Pytorch version: 1.10.2\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "MONAI rev id: 9db6e543d6090a3256f20695c1d3224df8cbbc0e\n",
      "MONAI __file__: C:\\Users\\Hripsime\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.8\n",
      "Nibabel version: 3.2.2\n",
      "scikit-image version: 0.19.2\n",
      "Pillow version: 9.0.1\n",
      "Tensorboard version: 2.6.0\n",
      "gdown version: 4.2.1\n",
      "TorchVision version: 0.11.3\n",
      "tqdm version: 4.63.0\n",
      "lmdb version: 1.3.0\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.4.1\n",
      "einops version: 0.4.0\n",
      "transformers version: 4.16.2\n",
      "mlflow version: 1.23.1\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "import time\n",
    "from ignite.handlers import EarlyStopping, ModelCheckpoint\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    Resized,\n",
    "    CropForegroundd,\n",
    "    RandScaleIntensityd,\n",
    "    DataStatsd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    Activationsd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandShiftIntensityd,\n",
    "    NormalizeIntensityd,\n",
    "    RandSpatialCropd,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    ScaleIntensityd,\n",
    "    SaveImaged,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Invertd,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from monai.optimizers import Novograd\n",
    "from monai.utils import get_torch_version_tuple, set_determinism\n",
    "from ignite.handlers import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "print_config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c0ea6b",
   "metadata": {},
   "source": [
    "## Setup data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3521153",
   "metadata": {},
   "source": [
    "## Set dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56786e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"C:/Users/Hripsime/OneDrive - ABYS MEDICAL/projects/CTPelvic1K_data/train_dir/\"\n",
    "\n",
    "train_images = sorted(glob.glob(os.path.join(train_dir, \"*data.nii.gz\")))\n",
    "train_labels = sorted(glob.glob(os.path.join(train_dir, \"*mask_4label.nii.gz\")))\n",
    "data_dicts = [{\"image\": image_name, \"mask\": label_name} for image_name, label_name in zip(train_images, train_labels)]\n",
    "train_files, val_files = data_dicts[:-10], data_dicts[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3ccee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86187e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"mask\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"mask\"]),\n",
    "        Orientationd(keys=[\"image\", \"mask\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\", \"mask\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        CropForegroundd(keys=[\"image\", \"mask\"], source_key=\"image\"),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=-120, a_max=360, b_min=0.0, b_max=1.0, clip=True,),\n",
    "        #DataStatsd(keys=[\"image\", \"mask\"], prefix='Data', data_type=True, data_shape=True, value_range=True, data_value=False),\n",
    "        \n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"mask\"],\n",
    "            label_key=\"mask\",\n",
    "            spatial_size=(128, 128, 128),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,),\n",
    "            \n",
    "        EnsureTyped(keys=[\"image\", \"mask\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"mask\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"mask\"]),\n",
    "        Orientationd(keys=[\"image\", \"mask\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\", \"mask\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=-120, a_max=360, b_min=0.0, b_max=1.0, clip=True,),\n",
    "        CropForegroundd(keys=[\"image\", \"mask\"], source_key=\"image\"),\n",
    "        \n",
    "        EnsureTyped(keys=[\"image\", \"mask\"]),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7259b163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████| 31/31 [04:51<00:00,  9.41s/it]\n",
      "Loading dataset: 100%|█████████████████████████████████████████████████████████████████| 10/10 [01:28<00:00,  8.84s/it]\n"
     ]
    }
   ],
   "source": [
    "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=0)\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49b03df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc #garbage collector\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b326fe30",
   "metadata": {},
   "source": [
    "## Create Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1db33978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.losses import DiceCELoss\n",
    "\n",
    "# standard PyTorch program style: create UNet, DiceLoss and Adam optimizer\n",
    "\n",
    "VAL_AMP = True #Automatic mixed precision to accelerate training speed and reduce a memory usage\n",
    "learning_rate = 2e-4\n",
    "\n",
    "device=torch.device(\"cuda:0\")     \n",
    "#device=torch.device(\"cpu\")      \n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=5,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)\n",
    "\n",
    "#loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "#optimizer = Novograd(model.parameters(), learning_rate * 10)\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "\n",
    "# define inference method\n",
    "def inference(input):\n",
    "\n",
    "    def _compute(input):\n",
    "        return sliding_window_inference(\n",
    "            inputs=input,\n",
    "            roi_size=(160, 160, 160),\n",
    "            sw_batch_size=4,\n",
    "            predictor=model,\n",
    "            overlap=0.5,\n",
    "        )\n",
    "\n",
    "    if VAL_AMP:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            return _compute(input)\n",
    "    else:\n",
    "        return _compute(input)\n",
    "    \n",
    "# use amp to accelerate training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "# enable cuDNN benchmark\n",
    "torch.backends.cudnn.benchmark = True    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9161bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import EarlyStopping\n",
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c022e3d",
   "metadata": {},
   "source": [
    "## Execute a PyTorch training process with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1c2c721",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 8.00 GiB total capacity; 5.29 GiB already allocated; 0 bytes free; 5.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     16\u001b[0m     batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m     17\u001b[0m     batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, labels)\n\u001b[0;32m     22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\networks\\nets\\unet.py:281\u001b[0m, in \u001b[0;36mUNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 281\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\monai\\networks\\blocks\\convolutions.py:324\u001b[0m, in \u001b[0;36mResidualUnit.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 324\u001b[0m     res: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresidual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# create the additive residual from x\u001b[39;00m\n\u001b[0;32m    325\u001b[0m     cx: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)  \u001b[38;5;66;03m# apply x to sequence of operations\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cx \u001b[38;5;241m+\u001b[39m res\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\torch\\nn\\modules\\conv.py:590\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\abys\\lib\\site-packages\\torch\\nn\\modules\\conv.py:585\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[0;32m    575\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    576\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    583\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    584\u001b[0m     )\n\u001b[1;32m--> 585\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 8.00 GiB total capacity; 5.29 GiB already allocated; 0 bytes free; 5.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "n_epochs = 100    \n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "avg_train_losses = []\n",
    "avg_valid_losses = [] \n",
    "\n",
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=5)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=5)])\n",
    "\n",
    "early_stopping = EarlyStopping(patience=20, verbose=True)\n",
    "    \n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    model.train() \n",
    "    for batch_data in train_loader:\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"mask\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    for val_data in val_loader:\n",
    "        val_inputs, val_labels = (\n",
    "            val_data[\"image\"].to(device),\n",
    "            val_data[\"mask\"].to(device),\n",
    "        )\n",
    "            \n",
    "       \n",
    "        val_outputs = inference(val_inputs)\n",
    "        val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "        val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "        loss_val = loss_function(val_outputs, val_labels)\n",
    "        valid_losses.append(loss_val.item())\n",
    "\n",
    "             \n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        \n",
    "        epoch_len = len(str(n_epochs))\n",
    "        \n",
    "        # print training/validation statistics\n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f}')\n",
    "        \n",
    "        print(print_msg)\n",
    "        \n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        \n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(valid_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "    # load the last checkpoint with the best model\n",
    "    torch.save(model.state_dict(), os.path.join(train_dir, \"best_metric_model.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1230ae9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba399695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9780b26",
   "metadata": {},
   "source": [
    "## Execute a PyTorch training process without Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40e3768c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/15\n",
      "1/14, train_loss: 2.7198\n",
      "2/14, train_loss: 2.6451\n",
      "3/14, train_loss: 2.6131\n",
      "4/14, train_loss: 2.5705\n",
      "5/14, train_loss: 2.5150\n",
      "6/14, train_loss: 2.5007\n",
      "7/14, train_loss: 2.4746\n",
      "8/14, train_loss: 2.4421\n",
      "9/14, train_loss: 2.4101\n",
      "10/14, train_loss: 2.3967\n",
      "11/14, train_loss: 2.3370\n",
      "12/14, train_loss: 2.3954\n",
      "13/14, train_loss: 2.2957\n",
      "14/14, train_loss: 2.3679\n",
      "15/14, train_loss: 2.3078\n",
      "epoch 1 average loss: 2.4661\n",
      "saved new best metric model\n",
      "current epoch: 1 current mean dice: 0.0612 best mean dice: 0.0612 at epoch 1 Total time seconds: 31.35\n",
      "----------\n",
      "epoch 2/15\n",
      "1/14, train_loss: 2.2905\n",
      "2/14, train_loss: 2.2591\n",
      "3/14, train_loss: 2.2795\n",
      "4/14, train_loss: 2.2333\n",
      "5/14, train_loss: 2.2339\n",
      "6/14, train_loss: 2.2632\n",
      "7/14, train_loss: 2.2602\n",
      "8/14, train_loss: 2.1670\n",
      "9/14, train_loss: 2.2260\n",
      "10/14, train_loss: 2.1862\n",
      "11/14, train_loss: 2.2460\n",
      "12/14, train_loss: 2.1600\n",
      "13/14, train_loss: 2.1570\n",
      "14/14, train_loss: 2.1603\n",
      "15/14, train_loss: 2.1448\n",
      "epoch 2 average loss: 2.2178\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.1300 best mean dice: 0.1300 at epoch 2 Total time seconds: 48.59\n",
      "----------\n",
      "epoch 3/15\n",
      "1/14, train_loss: 2.0652\n",
      "2/14, train_loss: 2.1078\n",
      "3/14, train_loss: 2.0798\n",
      "4/14, train_loss: 2.0441\n",
      "5/14, train_loss: 2.0478\n",
      "6/14, train_loss: 2.0603\n",
      "7/14, train_loss: 2.0290\n",
      "8/14, train_loss: 1.9961\n",
      "9/14, train_loss: 2.0454\n",
      "10/14, train_loss: 1.9621\n",
      "11/14, train_loss: 2.0357\n",
      "12/14, train_loss: 2.0088\n",
      "13/14, train_loss: 1.9503\n",
      "14/14, train_loss: 2.0053\n",
      "15/14, train_loss: 1.9071\n",
      "epoch 3 average loss: 2.0230\n",
      "saved new best metric model\n",
      "current epoch: 3 current mean dice: 0.1387 best mean dice: 0.1387 at epoch 3 Total time seconds: 65.76\n",
      "----------\n",
      "epoch 4/15\n",
      "1/14, train_loss: 1.9730\n",
      "2/14, train_loss: 1.9172\n",
      "3/14, train_loss: 1.8723\n",
      "4/14, train_loss: 1.9364\n",
      "5/14, train_loss: 1.8462\n",
      "6/14, train_loss: 1.9084\n",
      "7/14, train_loss: 1.9108\n",
      "8/14, train_loss: 1.8268\n",
      "9/14, train_loss: 1.8611\n",
      "10/14, train_loss: 1.8344\n",
      "11/14, train_loss: 1.8702\n",
      "12/14, train_loss: 1.8670\n",
      "13/14, train_loss: 1.8227\n",
      "14/14, train_loss: 1.7665\n",
      "15/14, train_loss: 1.8324\n",
      "epoch 4 average loss: 1.8697\n",
      "saved new best metric model\n",
      "current epoch: 4 current mean dice: 0.1720 best mean dice: 0.1720 at epoch 4 Total time seconds: 82.76\n",
      "----------\n",
      "epoch 5/15\n",
      "1/14, train_loss: 1.7454\n",
      "2/14, train_loss: 1.7571\n",
      "3/14, train_loss: 1.7645\n",
      "4/14, train_loss: 1.7542\n",
      "5/14, train_loss: 1.7589\n",
      "6/14, train_loss: 1.7087\n",
      "7/14, train_loss: 1.7283\n",
      "8/14, train_loss: 1.7477\n",
      "9/14, train_loss: 1.7147\n",
      "10/14, train_loss: 1.7344\n",
      "11/14, train_loss: 1.6589\n",
      "12/14, train_loss: 1.7014\n",
      "13/14, train_loss: 1.6449\n",
      "14/14, train_loss: 1.7408\n",
      "15/14, train_loss: 1.6773\n",
      "epoch 5 average loss: 1.7225\n",
      "saved new best metric model\n",
      "current epoch: 5 current mean dice: 0.2192 best mean dice: 0.2192 at epoch 5 Total time seconds: 99.61\n",
      "----------\n",
      "epoch 6/15\n",
      "1/14, train_loss: 1.5721\n",
      "2/14, train_loss: 1.7079\n",
      "3/14, train_loss: 1.6777\n",
      "4/14, train_loss: 1.5579\n",
      "5/14, train_loss: 1.6003\n",
      "6/14, train_loss: 1.5774\n",
      "7/14, train_loss: 1.5450\n",
      "8/14, train_loss: 1.5769\n",
      "9/14, train_loss: 1.5920\n",
      "10/14, train_loss: 1.4851\n",
      "11/14, train_loss: 1.5211\n",
      "12/14, train_loss: 1.5130\n",
      "13/14, train_loss: 1.5146\n",
      "14/14, train_loss: 1.5064\n",
      "15/14, train_loss: 1.4900\n",
      "epoch 6 average loss: 1.5625\n",
      "saved new best metric model\n",
      "current epoch: 6 current mean dice: 0.2311 best mean dice: 0.2311 at epoch 6 Total time seconds: 116.52\n",
      "----------\n",
      "epoch 7/15\n",
      "1/14, train_loss: 1.4839\n",
      "2/14, train_loss: 1.5080\n",
      "3/14, train_loss: 1.4798\n",
      "4/14, train_loss: 1.4454\n",
      "5/14, train_loss: 1.4498\n",
      "6/14, train_loss: 1.4071\n",
      "7/14, train_loss: 1.4485\n",
      "8/14, train_loss: 1.4034\n",
      "9/14, train_loss: 1.3999\n",
      "10/14, train_loss: 1.3872\n",
      "11/14, train_loss: 1.3454\n",
      "12/14, train_loss: 1.4366\n",
      "13/14, train_loss: 1.3420\n",
      "14/14, train_loss: 1.3496\n",
      "15/14, train_loss: 1.3228\n",
      "epoch 7 average loss: 1.4140\n",
      "saved new best metric model\n",
      "current epoch: 7 current mean dice: 0.2774 best mean dice: 0.2774 at epoch 7 Total time seconds: 133.42\n",
      "----------\n",
      "epoch 8/15\n",
      "1/14, train_loss: 1.3961\n",
      "2/14, train_loss: 1.2996\n",
      "3/14, train_loss: 1.3008\n",
      "4/14, train_loss: 1.3418\n",
      "5/14, train_loss: 1.3247\n",
      "6/14, train_loss: 1.2582\n",
      "7/14, train_loss: 1.3127\n",
      "8/14, train_loss: 1.2602\n",
      "9/14, train_loss: 1.3327\n",
      "10/14, train_loss: 1.2841\n",
      "11/14, train_loss: 1.2951\n",
      "12/14, train_loss: 1.2479\n",
      "13/14, train_loss: 1.2277\n",
      "14/14, train_loss: 1.2449\n",
      "15/14, train_loss: 1.1865\n",
      "epoch 8 average loss: 1.2875\n",
      "saved new best metric model\n",
      "current epoch: 8 current mean dice: 0.3234 best mean dice: 0.3234 at epoch 8 Total time seconds: 150.33\n",
      "----------\n",
      "epoch 9/15\n",
      "1/14, train_loss: 1.2136\n",
      "2/14, train_loss: 1.2558\n",
      "3/14, train_loss: 1.2253\n",
      "4/14, train_loss: 1.2449\n",
      "5/14, train_loss: 1.1974\n",
      "6/14, train_loss: 1.1945\n",
      "7/14, train_loss: 1.2249\n",
      "8/14, train_loss: 1.2067\n",
      "9/14, train_loss: 1.1768\n",
      "10/14, train_loss: 1.2489\n",
      "11/14, train_loss: 1.1830\n",
      "12/14, train_loss: 1.1717\n",
      "13/14, train_loss: 1.1875\n",
      "14/14, train_loss: 1.1759\n",
      "15/14, train_loss: 1.1783\n",
      "epoch 9 average loss: 1.2057\n",
      "saved new best metric model\n",
      "current epoch: 9 current mean dice: 0.3352 best mean dice: 0.3352 at epoch 9 Total time seconds: 167.22\n",
      "----------\n",
      "epoch 10/15\n",
      "1/14, train_loss: 1.1432\n",
      "2/14, train_loss: 1.1430\n",
      "3/14, train_loss: 1.1139\n",
      "4/14, train_loss: 1.1466\n",
      "5/14, train_loss: 1.0885\n",
      "6/14, train_loss: 1.1149\n",
      "7/14, train_loss: 1.1427\n",
      "8/14, train_loss: 1.0497\n",
      "9/14, train_loss: 1.0683\n",
      "10/14, train_loss: 1.0629\n",
      "11/14, train_loss: 1.1166\n",
      "12/14, train_loss: 1.1062\n",
      "13/14, train_loss: 1.0697\n",
      "14/14, train_loss: 1.0797\n",
      "15/14, train_loss: 1.0625\n",
      "epoch 10 average loss: 1.1006\n",
      "current epoch: 10 current mean dice: 0.2653 best mean dice: 0.3352 at epoch 9 Total time seconds: 184.27\n",
      "----------\n",
      "epoch 11/15\n",
      "1/14, train_loss: 1.0932\n",
      "2/14, train_loss: 1.1113\n",
      "3/14, train_loss: 1.1028\n",
      "4/14, train_loss: 1.1116\n",
      "5/14, train_loss: 1.0549\n",
      "6/14, train_loss: 1.0470\n",
      "7/14, train_loss: 1.0992\n",
      "8/14, train_loss: 1.0521\n",
      "9/14, train_loss: 1.0324\n",
      "10/14, train_loss: 1.0206\n",
      "11/14, train_loss: 1.0522\n",
      "12/14, train_loss: 1.0687\n",
      "13/14, train_loss: 1.0490\n",
      "14/14, train_loss: 1.0580\n",
      "15/14, train_loss: 1.0425\n",
      "epoch 11 average loss: 1.0664\n",
      "current epoch: 11 current mean dice: 0.3213 best mean dice: 0.3352 at epoch 9 Total time seconds: 201.25\n",
      "----------\n",
      "epoch 12/15\n",
      "1/14, train_loss: 0.9924\n",
      "2/14, train_loss: 1.0028\n",
      "3/14, train_loss: 1.0457\n",
      "4/14, train_loss: 1.0460\n",
      "5/14, train_loss: 0.9871\n",
      "6/14, train_loss: 1.0346\n",
      "7/14, train_loss: 1.0035\n",
      "8/14, train_loss: 1.0006\n",
      "9/14, train_loss: 0.9851\n",
      "10/14, train_loss: 1.0061\n",
      "11/14, train_loss: 0.9862\n",
      "12/14, train_loss: 1.0269\n",
      "13/14, train_loss: 0.9663\n",
      "14/14, train_loss: 0.9858\n",
      "15/14, train_loss: 0.9489\n",
      "epoch 12 average loss: 1.0012\n",
      "saved new best metric model\n",
      "current epoch: 12 current mean dice: 0.3699 best mean dice: 0.3699 at epoch 12 Total time seconds: 218.39\n",
      "----------\n",
      "epoch 13/15\n",
      "1/14, train_loss: 1.0154\n",
      "2/14, train_loss: 0.9842\n",
      "3/14, train_loss: 0.9544\n",
      "4/14, train_loss: 0.9608\n",
      "5/14, train_loss: 1.0012\n",
      "6/14, train_loss: 0.9689\n",
      "7/14, train_loss: 0.9479\n",
      "8/14, train_loss: 0.9774\n",
      "9/14, train_loss: 0.9292\n",
      "10/14, train_loss: 0.9318\n",
      "11/14, train_loss: 0.9570\n",
      "12/14, train_loss: 0.9488\n",
      "13/14, train_loss: 0.9236\n",
      "14/14, train_loss: 0.9869\n",
      "15/14, train_loss: 0.9249\n",
      "epoch 13 average loss: 0.9608\n",
      "saved new best metric model\n",
      "current epoch: 13 current mean dice: 0.4275 best mean dice: 0.4275 at epoch 13 Total time seconds: 235.36\n",
      "----------\n",
      "epoch 14/15\n",
      "1/14, train_loss: 0.9047\n",
      "2/14, train_loss: 0.9407\n",
      "3/14, train_loss: 0.9459\n",
      "4/14, train_loss: 0.9021\n",
      "5/14, train_loss: 0.9255\n",
      "6/14, train_loss: 0.9473\n",
      "7/14, train_loss: 0.9169\n",
      "8/14, train_loss: 0.9059\n",
      "9/14, train_loss: 0.8903\n",
      "10/14, train_loss: 0.9272\n",
      "11/14, train_loss: 0.9137\n",
      "12/14, train_loss: 0.9843\n",
      "13/14, train_loss: 0.9208\n",
      "14/14, train_loss: 0.8789\n",
      "15/14, train_loss: 0.8759\n",
      "epoch 14 average loss: 0.9187\n",
      "saved new best metric model\n",
      "current epoch: 14 current mean dice: 0.4910 best mean dice: 0.4910 at epoch 14 Total time seconds: 252.51\n",
      "----------\n",
      "epoch 15/15\n",
      "1/14, train_loss: 0.9343\n",
      "2/14, train_loss: 0.9383\n",
      "3/14, train_loss: 0.8891\n",
      "4/14, train_loss: 0.9015\n",
      "5/14, train_loss: 0.8626\n",
      "6/14, train_loss: 0.8383\n",
      "7/14, train_loss: 0.8878\n",
      "8/14, train_loss: 0.8505\n",
      "9/14, train_loss: 0.8814\n",
      "10/14, train_loss: 0.9308\n",
      "11/14, train_loss: 0.8321\n",
      "12/14, train_loss: 0.8331\n",
      "13/14, train_loss: 0.8179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14, train_loss: 0.9005\n",
      "15/14, train_loss: 0.9016\n",
      "epoch 15 average loss: 0.8800\n",
      "saved new best metric model\n",
      "current epoch: 15 current mean dice: 0.5305 best mean dice: 0.5305 at epoch 15 Total time seconds: 269.68\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "val_interval = 1   \n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=5)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=5)])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"mask\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        epoch_loss += loss.item()\n",
    "        print(\n",
    "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
    "            f\"train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"mask\"].to(device),\n",
    "                )\n",
    "                \n",
    "                val_outputs = inference(val_inputs)\n",
    "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                \n",
    "                # compute metric for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            \n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model.pth\"))\n",
    "                print(\"saved new best metric model\")\n",
    "            \n",
    "            print(\n",
    "                \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {} Total time seconds: {:.2f}\".format(epoch + 1, metric, best_metric, best_metric_epoch, (time.time()- start_time))\n",
    "                    )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd37bb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train completed, best_metric: 0.5305 at epoch: 15\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"train completed, best_metric: {best_metric:.4f} \"\n",
    "    f\"at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be4d0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
